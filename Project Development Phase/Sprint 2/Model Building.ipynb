{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ddbfbde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "c21e9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e7e7f",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8f8b9",
   "metadata": {},
   "source": [
    "Adding The Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3d0ddfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1d77577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0e136b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Datagen\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "# Testing Datagen\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "dadf473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory('/content/Dataset/training_set',target_size=(64,64), class_mode='categorical',batch_size=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f1b5fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory('/content/Dataset/test_set',target_size=(64,64),batch_size=200,\n",
    "                                          class_mode='categorical',color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ee809657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len x-train :  18\n"
     ]
    }
   ],
   "source": [
    "print(\"Len x-train : \", len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "849e034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len x-test :  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Len x-test : \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "3f4a8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9cf9bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2]\n",
      " [-2 -2]] is a kernel for detecting horizontal edges\n",
      "[[ 2 -2]\n",
      " [ 2 -2]] is a kernel for detecting vertical edges\n"
     ]
    }
   ],
   "source": [
    "# let img1 be an image with no features\n",
    "img1 = np.array([np.array([200, 200]), np.array([200, 200])])\n",
    "img2 = np.array([np.array([200, 200]), np.array([0, 0])])\n",
    "img3 = np.array([np.array([200, 0]), np.array([200, 0])])\n",
    "  \n",
    "kernel_horizontal = np.array([np.array([2, 2]), np.array([-2, -2])])\n",
    "print(kernel_horizontal, 'is a kernel for detecting horizontal edges')\n",
    "  \n",
    "kernel_vertical = np.array([np.array([2, -2]), np.array([2, -2])])\n",
    "print(kernel_vertical, 'is a kernel for detecting vertical edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "66cc1a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAExElEQVR4nO3bzculcxzH8c93QpOUp5SIyHJWFrMYSTbKRhayQik27PwDTLLwD1iYnZRMU5LdjI1iQzJZKLMbUVJYejY/i/ume3E3MQ/3+czt9apT51xd5+p7Oufd7zpPs9YK0OfApgcAdidOKCVOKCVOKCVOKCVOKCXOUjPzxcw8uOk52BxxllprHVprfXCpjzszx2bmzMycm5mnL/XxuXTE+f/zeZLnk3y26UE4v6s2PQC7m5mzSZ5Ncn+SQ0l+TfJokrNJHtu+vLC9/Zm11qnt+92d5I0k9yb5OMmZJNevtZ5MkrXWa9v7/bJ3j4YLYeW8MjyS5M0kNyY5neRktp6725O8nOT1Hfu+leSTJDcnOZrkqb0clEtHnFeGD9daJ9dafyQ5keSWJK+utX5P8naSu2bmhpm5M8nhJC+utX5ba32U5L3Njc3FEOeV4bsd139O8v1a688dt5PkuiS3JflxrfXTjv2/3oP5uAzEub98m+Smmbl2x7Y7NjUMF0ec+8ha66sknyY5OjPXzMyRbL1f/cf29oNJJsnVM3NwZrwOCnlS9p8nkhxJ8kOSV5Icz9Ynun87la1T4fuSHNu+/sAez8i/MP5svb/NzPEkX661Xtr0LPw3Vs59ZmYOz8w9M3NgZh7O1nej7254LC6AHyHsP7cmeSdb33N+k+S5tdbpzY7EhXBaC6Wc1kKp857WPnTgccsqXGbvnzsxu223ckIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUIpcUKpWWttegZgF1ZOKCVOKCVOKCVOKCVOKCVOKPUXV4959KCnMpoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal edge confidence score: 0\n",
      "Vertical edge confidence score: 0\n"
     ]
    }
   ],
   "source": [
    "def apply_kernel(img, kernel):\n",
    "    return np.sum(np.multiply(img, kernel))\n",
    "  \n",
    "# Visualizing img1\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')\n",
    "plt.title('img1')\n",
    "plt.show()\n",
    "\n",
    "# Checking for horizontal and vertical features in image1\n",
    "print('Horizontal edge confidence score:', apply_kernel(img1, \n",
    "                                            kernel_horizontal))\n",
    "print('Vertical edge confidence score:', apply_kernel(img1, \n",
    "                                            kernel_vertical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d6bef2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFB0lEQVR4nO3azavmcxjH8c81yUKM58hTSVjMhsUsRLIRG0mWWIiNpbKwI/EvKEuRaTbCDhsbC1JWipSIQswsJLLga3EfdZqOyWhm7o/j9aq7zvmd3/nd193p3XU/nFlrBehzYNsDAHsTJ5QSJ5QSJ5QSJ5QSJ5QSZ6mZ+WRm7tr2HGyPOEuttQ6ttd47ndecmZtm5s2Z+WFmjs/M2zNz8+m8D04fcf6/XJTkrSQ3J7kiyYdJ3tzmQPy98R9CnWbmyySPJ7kjyaEkvyW5P8mXSR7cuT25c/yxtdY7O793fZKXk9ya5IMknyW5cK318B73cUmSY0kuW2sdO7OPiFNlc/433JfklSQXJ/k4ydvZ/O2uTvJckpd2nftaNhvx0iTPJnnkJNe9M8l3wuxkc5Y6YXPevta6e+f4fUmOZLMNf5+ZC5L8lE24B5N8keTgWuuXnfNfTZITN+fMXJPNZn1qrXXkrDwoTonN+d/w/a6vf03y41rr913fJ8n5Sa5KcvyvMHd8feLFZubyJO8keVGYvcS5v3yb5JKZOW/XsWt3nzAzF2cT5ltrrRfO5nCcGnHuI2utr5J8lOTZmTl3Zm7L5vVqkmRmDmbzevX9tdbTWxqTf0ic+89DSW7L5l3Y55MczeYd3SR5IMnhJI/OzM+7btdtZ1ROxhtC+9zMHE3y6VrrmW3PwqmxOfeZmTk8MzfMzIGZuTebz0bf2PJY/AvnbHsATrsrk7yezeec3yR5Yq318XZH4t/wtBZKeVoLpU76tPaP7260VuEMO3Dl57Pn8bM9CPDPiBNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKiRNKnXOyH95z1S1naQz4/3r3j72P25xQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQSpxQatZa254B2IPNCaXECaXECaXECaXECaXECaX+BHW+mUCWKS4/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal edge confidence score: 800\n",
      "Vertical edge confidence score: 0\n"
     ]
    }
   ],
   "source": [
    "# Visualizing img2\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.title('img2')\n",
    "plt.show()\n",
    "\n",
    "# Checking for horizontal and vertical features in image2\n",
    "print('Horizontal edge confidence score:', apply_kernel(img2, \n",
    "                                            kernel_horizontal))\n",
    "print('Vertical edge confidence score:', apply_kernel(img2, \n",
    "                                            kernel_vertical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9bf9b5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFOUlEQVR4nO3awYudZxnG4fuJWqNopFFUUqTYopsu2o2gJAsXagsliGt1141/QeuqoX9CwYVQSouhIQRE3IkuRBBpEQKGQqUgkYjVYEQUbKAmbxczgSEOCRknOXfG61rNfOc73zyH4cf7nu+cWWsF6HNo0wMAuxMnlBInlBInlBInlBInlBJnqZl5c2a+uuk52BxxllprPbbW+uV+XnNmPjUzv56ZKzPzj5n5zcwc38+/wf4ZX0L4/zEzh5M8nOTtJCvJN5O8nOTTa63/bHI2/puVs9TMXJyZr83MqZk5NzOnZ+ZfM3NhZr44M9+fmcszc2lmvrHjeZ+fmV9tn/uLmfnBzJxOkrXW1bXW79da15NMkmtJHkxydDOvklsR5/3hZJIfZSuk80l+lq3/3UNJXkjywx3nvpbkjSSfTHIqyXdvvtjM/C7J1SQ/TfLSWuvyXZydPbKtLTUzF5M8k+REkuNrra9vHz+Z5EyST6y1rs3Mx5P8M1vhHknyhyRH1lr/3j7/xqr5nZuufzjJt5I8sNZ69Z68KO6IlfP+8NcdP7+b5G9rrWs7fk+SjyU5luTvN8Lcdmm3C25vcc8keW5mHt/vgfnfifNgeSfJ0Zn56I5jn7vNcz6U5JG7NxJ7Jc4DZK31xyS/TXJqZh6Yma9k6/1qkmRmvjwzJ7Yf+8jMPJvkM0le39DI3MIHNz0A++7bSV5JciVbN4bOJvnA9mMfTvJitlbK95JcSPL0WuvP935MbscNoQNuZs4meWut9fymZ+HO2NYeMDPzpZl5dGYOzcxT2fqiwU82PBZ7YFt78Hw2yY+z9Tnnn5J8b611frMjsRe2tVDKthZK3XJbe/0vX7Cs3meePPbEpkfgDv38+rnZ7biVE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0rNWmvTMwC7sHJCKXFCKXFCKXFCKXFCKXFCqfcBLDufqvQo0psAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal edge confidence score: 0\n",
      "Vertical edge confidence score: 800\n"
     ]
    }
   ],
   "source": [
    "# Visualizing img3\n",
    "plt.imshow(img3)\n",
    "plt.axis('off')\n",
    "plt.title('img3')\n",
    "plt.show()\n",
    "  \n",
    "# Checking for horizontal and vertical features in image3\n",
    "print('Horizontal edge confidence score:', apply_kernel(img3, \n",
    "                                            kernel_horizontal))\n",
    "print('Vertical edge confidence score:', apply_kernel(img3, \n",
    "                                            kernel_vertical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c041ad75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Class Indices in Training Dataset\n",
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "214c30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b02306f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "882aab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b876545",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "4a5d0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ba151",
   "metadata": {},
   "source": [
    "# Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "2d67694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Conv2D(33,(3,3),input_shape=(64,64,1), activation='relu'))\n",
    "\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156f710",
   "metadata": {},
   "source": [
    "# 1st hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "9da67fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(400,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685da32",
   "metadata": {},
   "source": [
    "# 2nd hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "12f00b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953d5a0",
   "metadata": {},
   "source": [
    "# 3rd hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "43c2b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afbfa1",
   "metadata": {},
   "source": [
    "# output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "69161199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8d206",
   "metadata": {},
   "source": [
    "# Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "f5a3858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de25ba",
   "metadata": {},
   "source": [
    "# Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8b2b9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harini\\AppData\\Local\\Temp/ipykernel_13792/4028576845.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=30,epochs=10,validation_data=x_test,validation_steps=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/30 [=================>............] - ETA: 57s - loss: 1.2575 - accuracy: 0.5933 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "30/30 [==============================] - 107s 3s/step - loss: 1.2575 - accuracy: 0.5933 - val_loss: 0.4059 - val_accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238f9346100>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=30,epochs=10,validation_data=x_test,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "9c1719c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 53s 3s/step - loss: 0.2315 - accuracy: 0.9316 - val_loss: 0.2413 - val_accuracy: 0.9338\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 52s 3s/step - loss: 0.0777 - accuracy: 0.9781 - val_loss: 0.2032 - val_accuracy: 0.9556\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 53s 3s/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.1937 - val_accuracy: 0.9707\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 53s 3s/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.1634 - val_accuracy: 0.9742\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 53s 3s/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.1722 - val_accuracy: 0.9764\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 51s 3s/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.1862 - val_accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 52s 3s/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.2045 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 52s 3s/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.2209 - val_accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 53s 3s/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1856 - val_accuracy: 0.9769\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 53s 3s/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.1958 - val_accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238b9e39e50>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,epochs=10,validation_data=x_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49980b",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "ce98c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aslpng1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
